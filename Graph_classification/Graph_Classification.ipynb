{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing...\n",
      "Done importing\n"
     ]
    }
   ],
   "source": [
    "print(\"Importing...\")\n",
    "from GCN import *\n",
    "from datetime import datetime\n",
    "from utils.my_utils import *\n",
    "from utils.util import *\n",
    "import time\n",
    "from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n",
    "import os\n",
    "import math\n",
    "from train_utils import *\n",
    "\n",
    "torch.manual_seed(124)\n",
    "np.random.seed(124)\n",
    "print(\"Done importing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings\n",
      "The calculations will be performed on the device: cuda:0\n",
      "Results will be saved in: C:\\Users\\mande\\Desktop\\Erasmus\\ComputerSecurity\\3D_STEP_classification\\results\\runs_GCN\\Test_dataset\n",
      "    The model will be saved as: C:\\Users\\mande\\Desktop\\Erasmus\\ComputerSecurity\\3D_STEP_classification\\results\\runs_GCN\\Test_dataset/Models/Test_dataset_09-30\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings\")\n",
    "\n",
    "run_folder=\"../\"\n",
    "dataset = \"Test_dataset\"\n",
    "STEP_dataset= dataset + \"/STEP_models/\"\n",
    "graphml_dataset = dataset + \"/graphml_models/\"\n",
    "learning_rate=0.0005\n",
    "batch_size=1\n",
    "num_epochs=50\n",
    "dropout=0.5\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"The calculations will be performed on the device:\", device)\n",
    "\n",
    "# save paths\n",
    "model_name = dataset + \"_\" + str(datetime.today().strftime('%m-%d'))\n",
    "out_dir = os.path.abspath(os.path.join(run_folder, \"./results/runs_GCN\", dataset))\n",
    "if not os.path.exists(out_dir + \"/Models/\"):\n",
    "    os.makedirs(out_dir + \"/Models/\")\n",
    "save_path = out_dir + \"/Models/\" + model_name\n",
    "print(\"Results will be saved in:\", out_dir)\n",
    "print(\"    The model will be saved as:\", save_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CONVERT STEP 3D Models to GRAPHS\n",
    "To convert STEP models into Graphml data we use the **make_graphh_dataset** Python scripts. It generates an indirect graph from each STEP file.\n",
    "The function takes two input: 1) the path of the STEP dataset and 2) the output directory where it's gonna write the graph dataset.\n",
    "To avoid generating each graphs every run, the graph are saved as a **.graphml** format and then reload at subsequent runs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting STEP dataset in Graphml dataset\n",
      "Loading 0/0_10.stp graph\n",
      "Loading 0/0_11.stp graph\n",
      "Loading 0/0_12.stp graph\n",
      "Loading 0/0_13.stp graph\n",
      "Loading 0/0_2.stp graph\n",
      "Loading 0/0_3.stp graph\n",
      "Loading 0/0_4.stp graph\n",
      "Loading 0/0_5.stp graph\n",
      "Loading 0/0_6.stp graph\n",
      "Loading 0/0_7.stp graph\n",
      "Loading 0/0_8.stp graph\n",
      "Loading 0/0_9.stp graph\n",
      "Loading 1/1_0.stp graph\n",
      "Loading 1/1_1.stp graph\n",
      "Loading 1/1_10.stp graph\n",
      "Loading 1/1_11.stp graph\n",
      "Loading 1/1_2.stp graph\n",
      "Loading 1/1_3.stp graph\n",
      "Loading 1/1_4.stp graph\n",
      "Loading 1/1_5.stp graph\n",
      "Loading 1/1_6.stp graph\n",
      "Loading 1/1_7.stp graph\n",
      "Loading 1/1_8.stp graph\n",
      "Loading 1/1_9.stp graph\n",
      "Done converting\n"
     ]
    }
   ],
   "source": [
    "from Graph_convertion.step_2_graph import make_graphh_dataset\n",
    "\n",
    "print(\"Converting STEP dataset in Graphml dataset\")\n",
    "make_graphh_dataset(os.path.abspath(os.path.join(run_folder,\"Datasets\",STEP_dataset)), os.path.abspath(os.path.join(run_folder,\"Datasets\",graphml_dataset)))\n",
    "print(\"Done converting\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### We load the graph dataset\n",
    "The list of all graph is loaded and divided in train, test and validation set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Graph data...\n",
      "Loading class: 0\n",
      "Loading class: 1\n",
      "# classes: 2\n",
      "# maximum node tag: 72\n",
      "# data: 24\n",
      "# training graphs:  18\n",
      "class: 0  - num elements: 9 elements:  ['0_12.graphml', '0_9.graphml', '0_2.graphml', '0_13.graphml', '0_10.graphml', '0_7.graphml', '0_6.graphml', '0_5.graphml', '0_3.graphml']\n",
      "class: 1  - num elements: 9 elements:  ['1_2.graphml', '1_6.graphml', '1_8.graphml', '1_5.graphml', '1_1.graphml', '1_9.graphml', '1_10.graphml', '1_7.graphml', '1_0.graphml']\n",
      "# validation graphs:  3\n",
      "class: 0  - num elements: 1 elements:  ['0_11.graphml']\n",
      "class: 1  - num elements: 2 elements:  ['1_11.graphml', '1_4.graphml']\n",
      "# test graphs:  3\n",
      "class: 0  - num elements: 2 elements:  ['0_4.graphml', '0_8.graphml']\n",
      "class: 1  - num elements: 1 elements:  ['1_3.graphml']\n",
      "Loading data... finished!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Graph data...\")\n",
    "use_degree_as_tag = False\n",
    "fold = 0\n",
    "graphs, num_classes = my_load_data(graphml_dataset, use_degree_as_tag)\n",
    "\n",
    "train_graphs, test_graphs = separate_data(graphs, fold)\n",
    "train_graphs, valid_graphs = split_data(train_graphs, perc=0.9)\n",
    "print(\"# training graphs: \", len(train_graphs))\n",
    "print_data_commposition(train_graphs)\n",
    "print(\"# validation graphs: \", len(valid_graphs))\n",
    "print_data_commposition(valid_graphs)\n",
    "print(\"# test graphs: \", len(test_graphs))\n",
    "print_data_commposition(test_graphs)\n",
    "# Num of different STEP entities founded in the graph dataset\n",
    "feature_dim_size = graphs[0].node_features.shape[1]\n",
    "print(\"Loading data... finished!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model\n",
    "We create a Graph Convolutional Neural Network model: the convolutional layers are followed by an attention mechanism and finally by fully connected layers."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating model\")\n",
    "\n",
    "# Create a GCN model\n",
    "model = GCN_CN_v4(feature_dim_size=feature_dim_size, num_classes=num_classes, dropout=dropout).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "num_batches_per_epoch = int((len(train_graphs) - 1) / batch_size) + 1\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=num_batches_per_epoch, gamma=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main process\n",
      "Writing to C:\\Users\\mande\\Desktop\\Erasmus\\ComputerSecurity\\3D_STEP_classification\\results\\runs_GCN\\Test_dataset\n",
      "\n",
      "| epoch   1 | time:  0.35s | train loss  0.53 | valid loss  0.57 | valid acc 100.00 | \n",
      "Save at epoch:   1 at valid loss:  0.57 and valid accuracy: 100.00\n"
     ]
    }
   ],
   "source": [
    "print(\"Main process\")\n",
    "\n",
    "print(\"Writing to {}\\n\".format(out_dir))\n",
    "# Checkpoint directory\n",
    "checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "write_acc = open(checkpoint_prefix + '_acc.txt', 'w')\n",
    "\n",
    "train_losses = []\n",
    "train_accuracy = []\n",
    "valid_losses = []\n",
    "valid_accuracy = []\n",
    "valid_accuracy_x_class = []\n",
    "\n",
    "best_loss = math.inf\n",
    "best_accuracy = 0\n",
    "# Train loop\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    # train model\n",
    "    train(mmodel=model, optimizer=optimizer, train_graphs=train_graphs, batch_size=batch_size, num_classes=num_classes, device=device)\n",
    "    # evaluate on train data\n",
    "    train_loss, train_acc, _ = evaluate(mmodel=model, current_graphs=train_graphs, batch_size=batch_size, num_classes=num_classes, device=device, out_dir=out_dir)\n",
    "    # evaluate on validation data\n",
    "    valid_loss, valid_acc, valid_acc_x_class = evaluate(mmodel=model, current_graphs=valid_graphs, batch_size=batch_size, num_classes=num_classes, device=device, out_dir=out_dir)\n",
    "    print('| epoch {:3d} | time: {:5.2f}s | train loss {:5.2f} | valid loss {:5.2f} | valid acc {:5.2f} | '.format(epoch, (time.time() - epoch_start_time), train_loss, valid_loss, valid_acc*100))\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracy.append(train_acc)\n",
    "    valid_losses.append(valid_loss)\n",
    "    valid_accuracy.append(valid_acc)\n",
    "    valid_accuracy_x_class.append(valid_acc_x_class)\n",
    "\n",
    "    # Make a step of the optimizer if the mean of the last 6 epochs were better than the current epoch\n",
    "    if epoch > 5 and train_losses[-1] > np.mean(train_losses[-6:-1]):\n",
    "        scheduler.step()\n",
    "        print(\"Scheduler step\")\n",
    "    # save if best performance ever\n",
    "    if best_accuracy < valid_acc or (best_accuracy == valid_acc and best_loss > valid_loss):\n",
    "        print(\"Save at epoch: {:3d} at valid loss: {:5.2f} and valid accuracy: {:5.2f}\".format(epoch, valid_loss, valid_acc*100))\n",
    "        best_accuracy = valid_acc\n",
    "        best_loss = valid_loss\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    write_acc.write('epoch ' + str(epoch) + ' fold ' + str(fold) + ' acc ' + str(valid_acc*100) + '%\\n')\n",
    "\n",
    "print(\"Finished training\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot results\n",
      "Accuracy per class :\n",
      "[100. 100.]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_21136\\2708024597.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;31m# Evaluate on test data\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_state_dict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msave_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m \u001B[0mtest_loss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_acc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mevaluate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmmodel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcurrent_graphs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtest_graphs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_classes\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mnum_classes\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mout_dir\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mout_dir\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlast_round\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Evaluate: loss on test: \"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_loss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\" and accuracy: \"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_acc\u001B[0m \u001B[1;33m*\u001B[0m \u001B[1;36m100\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Erasmus\\ComputerSecurity\\3D_STEP_classification\\Graph_classification\\train_utils.py\u001B[0m in \u001B[0;36mevaluate\u001B[1;34m(mmodel, current_graphs, batch_size, num_classes, device, out_dir, last_round)\u001B[0m\n\u001B[0;32m    143\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    144\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mtotal_loss\u001B[0m\u001B[1;33m/\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcurrent_graphs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maccuracy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0macc_x_class\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Erasmus\\ComputerSecurity\\3D_STEP_classification\\Graph_classification\\train_utils.py\u001B[0m in \u001B[0;36mevaluate\u001B[1;34m(mmodel, current_graphs, batch_size, num_classes, device, out_dir, last_round)\u001B[0m\n\u001B[0;32m    143\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    144\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mtotal_loss\u001B[0m\u001B[1;33m/\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcurrent_graphs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maccuracy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0macc_x_class\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_37_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_37_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_37_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_37_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_37_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_37_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_37_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_37_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_37_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_37_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2021.3\\plugins\\python\\helpers\\pydev\\pydevd.py\u001B[0m in \u001B[0;36mdo_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1145\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1146\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_threads_suspended_single_notification\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnotify_thread_suspended\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread_id\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstop_reason\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1147\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_do_wait_suspend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1148\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1149\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_do_wait_suspend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mthread\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2021.3\\plugins\\python\\helpers\\pydev\\pydevd.py\u001B[0m in \u001B[0;36m_do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1160\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1161\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprocess_internal_commands\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1162\u001B[1;33m                 \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0.01\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1163\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1164\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcancel_async_evaluation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mget_current_thread_id\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mid\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Plot results\")\n",
    "\n",
    "valid_accuracy_x_class = np.array(valid_accuracy_x_class).T\n",
    "# plot training flow\n",
    "plot_training_flow(ys=[train_losses, valid_losses], names=[\"train\", \"validation\"], path=out_dir, fig_name=\"/losses_flow\", y_axis=\"Loss\")\n",
    "plot_training_flow(ys=[np.array(train_accuracy)*100, np.array(valid_accuracy)*100], names=[\"train\",\"validation\"], path=out_dir, fig_name=\"/accuracy_flow\", y_axis=\"Accuracy\")\n",
    "# Evaluate on test data\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "test_loss, test_acc, _ = evaluate(mmodel=model, current_graphs=test_graphs, batch_size=batch_size, num_classes=num_classes, device=device, out_dir=out_dir, last_round=True)\n",
    "print(\"Evaluate: loss on test: \", test_loss, \" and accuracy: \", test_acc * 100)\n",
    "\n",
    "write_acc.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}